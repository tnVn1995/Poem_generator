{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shakespeare-style Poem Generator\n",
    "\n",
    "Building a poem generator whose style based on the Sonnets written by Shakespeare. This is a character-level model where the predicted output will be a character based on previous seen characters. The formal question is: Given a character, or a sequence of characters, what is the most probable next character?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T05:03:17.279929Z",
     "start_time": "2020-04-07T05:03:17.274942Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import io\n",
    "import sys\n",
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "# Model Building\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T04:22:43.206349Z",
     "start_time": "2020-04-07T04:22:43.200365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "THE SONNETS\n",
      "\n",
      "by William Shakespeare\n",
      "\n",
      "From fairest creatures we desire increase,\n",
      "That thereby beauty's rose might never die,\n",
      "But as the riper should by time decease,\n",
      "His tender heir might bear his mem\n"
     ]
    }
   ],
   "source": [
    "def load_text(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        text = f.read()\n",
    "    return text\n",
    "\n",
    "file_poem = 'data/shakespeare_poems.txt' # Path of the file\n",
    "\n",
    "text = load_text(file_poem)\n",
    "\n",
    "print(text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T04:17:44.273684Z",
     "start_time": "2020-04-07T04:17:44.267063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct characters: 61\n"
     ]
    }
   ],
   "source": [
    "# Get unique characters from the texts\n",
    "chars = sorted(list(set(text)))\n",
    "print('Number of distinct characters:', len(chars))\n",
    "\n",
    "# Mapping unique characters to unique integer\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "# Mapping unique integer to unique characters\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The poem generator predicts the next character based on the previous characters. Thus, we will generate our set of data using the original texts by creating sequences differed from each other by 1 character. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T04:49:21.075229Z",
     "start_time": "2020-04-07T04:49:21.022390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sequences: 93979\n"
     ]
    }
   ],
   "source": [
    "max_len_chars = 40\n",
    "\n",
    "step = 1\n",
    "\n",
    "# Training data\n",
    "sentences = []\n",
    "# Labels\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - max_len_chars, step):\n",
    "\n",
    "    sentences.append(text[i: i + max_len_chars])\n",
    "\n",
    "    next_chars.append(text[i + max_len_chars])\n",
    "\n",
    "print('number of sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T04:52:38.140475Z",
     "start_time": "2020-04-07T04:52:38.129506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second sample sequence:\n",
      "\n",
      "THE SONNETS\n",
      "\n",
      "by William Shakespeare\n",
      "\n",
      "Fro\n",
      "Target label:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'m'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Third sample sequence:\n",
      "\n",
      "HE SONNETS\n",
      "\n",
      "by William Shakespeare\n",
      "\n",
      "From\n",
      "Target label:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Second sample sequence:\\n')\n",
    "print(sentences[1])\n",
    "print('Target label:')\n",
    "display(next_chars[1])\n",
    "print('==='*30)\n",
    "print('Third sample sequence:\\n')\n",
    "print(sentences[2])\n",
    "print('Target label:')\n",
    "display(next_chars[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target label is the next character following 40 characters in a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T04:52:41.031538Z",
     "start_time": "2020-04-07T04:52:41.024559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\nTHE SONNETS\\n\\nby William Shakespeare\\n\\nFr',\n",
       " 'THE SONNETS\\n\\nby William Shakespeare\\n\\nFro',\n",
       " 'HE SONNETS\\n\\nby William Shakespeare\\n\\nFrom',\n",
       " 'E SONNETS\\n\\nby William Shakespeare\\n\\nFrom ',\n",
       " ' SONNETS\\n\\nby William Shakespeare\\n\\nFrom f']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Sample data:')\n",
    "sentences[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a training data with length of 40 characters for each sequence. We simply create a sliding window of 1 character on the whole text. The window slides on the whole text to create sequences different from each other by 1 character. \n",
    "\n",
    "**Note**: \n",
    "- The slide of window is a hyperparameter. The smaller the number is, the more computationally expensive the model is and the better the model perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Sequences for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T04:27:11.870723Z",
     "start_time": "2020-04-07T04:27:09.937510Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), max_len_chars, len(chars)), dtype=np.bool)\n",
    "\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "\n",
    "    for t, char in enumerate(sentence):\n",
    "\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "\n",
    "        y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T05:21:28.386030Z",
     "start_time": "2020-04-07T05:21:28.377036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first vector as text:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'THE SONNETS\\n\\nby William Shakespeare\\n\\nFro'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "The first sequence as vector:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 2, 1, 0, 0, 3, 2, 0, 0, 1, 0, 3, 1, 0, 0, 3, 0, 0, 1, 2,\n",
       "       0, 1, 2, 1, 0, 1, 1, 0, 2, 1, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('The first vector as text:')\n",
    "display(text[1:41])\n",
    "print('==='*30)\n",
    "print('The first sequence as vector:')\n",
    "display(sum(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T04:53:52.928463Z",
     "start_time": "2020-04-07T04:53:52.922477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 61)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of each example\n",
    "x[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each example in the training matrix is of shape (40, 61), which corresponds to a sequence with 40 character long in a text with 61 unique characters. As shown above, the first unique character in our first vector sequence corresponds to the first item in our chars set, which is '\\n'. There are 4 of them in the first sequence. Similarly, there are 3 whitespace (' ') in the first sequence. And so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T04:43:15.611649Z",
     "start_time": "2020-04-07T04:43:15.606665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first label as vector:\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False]\n"
     ]
    }
   ],
   "source": [
    "print('The first label as vector:')\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T04:41:56.269413Z",
     "start_time": "2020-04-07T04:41:56.263427Z"
    }
   },
   "source": [
    "Each example in the label set is of shape (61,), corresponding to 61 unique characters in the text corpus. Since our model aims to predict the next character in the text corpus given the previous 40 characters, our label example is a boolean vector of shape 61. Except for the target label, all other values are default to False. In the above example, the target label is 'o'. Since 'o' corresponds to index 49, we see that only at position 49th in our first label, the value is True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T05:20:15.942485Z",
     "start_time": "2020-04-07T05:20:15.661975Z"
    }
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T05:32:09.231694Z",
     "start_time": "2020-04-07T05:24:48.451937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\nlpiaenv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\nlpiaenv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "93979/93979 [==============================] - 58s 612us/sample - loss: 2.0129\n",
      "Epoch 2/10\n",
      "93979/93979 [==============================] - 43s 457us/sample - loss: 1.7293\n",
      "Epoch 3/10\n",
      "93979/93979 [==============================] - 44s 464us/sample - loss: 1.6483\n",
      "Epoch 4/10\n",
      "93979/93979 [==============================] - 42s 450us/sample - loss: 1.6143\n",
      "Epoch 5/10\n",
      "93979/93979 [==============================] - 42s 445us/sample - loss: 1.5918\n",
      "Epoch 6/10\n",
      "93979/93979 [==============================] - 42s 449us/sample - loss: 1.5742\n",
      "Epoch 7/10\n",
      "93979/93979 [==============================] - 42s 447us/sample - loss: 1.5634\n",
      "Epoch 8/10\n",
      "93979/93979 [==============================] - 42s 447us/sample - loss: 1.5596\n",
      "Epoch 9/10\n",
      "93979/93979 [==============================] - 42s 445us/sample - loss: 1.5523\n",
      "Epoch 10/10\n",
      "93979/93979 [==============================] - 42s 447us/sample - loss: 1.5443\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(128, input_shape=(max_len_chars, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "model.fit(x, y,batch_size=128,epochs=10)\n",
    "\n",
    "model.save(\"poem_gen_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T06:08:43.162175Z",
     "start_time": "2020-04-07T06:08:43.157220Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.engine.sequential.Sequential"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T06:42:36.625172Z",
     "start_time": "2020-04-07T06:42:23.737674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed sentence: e, and born of thee,\n",
      "In others' works th\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"e, and born of thee,\\nIn others' works that I love hath thy sear,\\nxThe dreams, I, leavy the itliving it and rine,\\nBut for me eveisy catel did is thus the hrows\\nIfty I (death in venges it forbead morred:\\nShall oncemy praisest both hate ill gardens:\\nFor youth be thinute him thy constca didring.\\nNo not strength that eyes I day misprits.\\n\\nAd so alt sinfent in these facoust, see.\\nFor look on my stance no tongue coof ill?\\nI love will a mear's \""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from typing import List\n",
    "from IPython.core.debugger import set_trace\n",
    "model = load_model('poem_gen_model.h5')\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"helper function to sample an index from a probability array\n",
    "    using the multinomial distribution\"\"\"\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def generate_poem(model: Sequential , num_chars_to_generate: int =400,\n",
    "                  max_len_chars: int =40, chars: List['str'] =chars):\n",
    "    \"\"\"Using a trained model to generate texts randomly drawn from the Somnet\"\"\"\n",
    "    start_index = random.randint(0, len(text) - max_len_chars - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + max_len_chars]\n",
    "    generated += sentence\n",
    "    print(\"Seed sentence: {}\".format(generated))\n",
    "    for i in range(num_chars_to_generate):\n",
    "        x_pred = np.zeros((1, max_len_chars, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "            \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds, 1)\n",
    "        next_char = indices_char[next_index]\n",
    "#         set_trace()\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "    return generated\n",
    "\n",
    "generate_poem(model, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The trained model does not do a good job of predicting text from the Sonnets. Some words are simply random like oncemy, thinute, etc. Sentences are not coherent yet. There are a couple of things we could do to improve the accuracy. For example:\n",
    "- Stacking more layers,\n",
    "- Tweak the temperature variable,\n",
    "- Train for more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('nlpiaenv': conda)",
   "language": "python",
   "name": "python361064bitnlpiaenvconda61f04f74d93d4de799586f1d9c3027f4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
